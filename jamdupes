#!/usr/bin/env python3
# -*- coding: utf-8 -*-

__author__ = "Jim Male <jmale1@gmail.com>"
__copyright__ = "Copyright (c) 2016"
__credits__ = ["Jim Male <jmale1@gmail.com>"]
__license__ = "BSD-3"

import os
import sys
import math
import argparse
import hashlib
import collections

try:
	import progressbar
except ImportError:
	progressbar = None

class jamdupesDictionary(collections.defaultdict):
	def __init__(self):
		self.default_factory = list
	def __init__(self, collection):
		self.default_factory = list
		for item in collection:
			assert(type(item) == jamdupesFile)
			self.insertJamdupesFile(item)
	def trimKeysWithOnlyOneValue(self):
		tmpkeys = list(self.keys())
		for key in tmpkeys:
			if (len(self[key]) <= 1):
				del self[key]
	def trimZeroKey(self):
		if (0 in self.keys()):
			del self[0]
	def insertJamdupesFile(self, jdFile):
		self[jdFile.size()].append(jdFile)


## helpful help from
## http://pythoncentral.io/how-to-sort-a-list-tuple-or-object-with-sorted-in-python/
class jamdupesFile:
	def __init__(self, path):
		self.path = path
		self.hash = ''

	def __repr__(self):
		return '<{}: {}>'.format(self.__class__.__name__, self.path)

	def __lt__(self, other):
		return self.path < other.path

	def __le__(self, other):
		return (self.path < other.path) or (self.__eq__(other))

	def __eq__(self, other):
		return os.path.samefile(self.path, other.path)

	def __ne__(self, other):
		return (not __eq__(other))

	def __gt__(self, other):
		return self.path > other.path

	def __ge__(self, other):
		return (self.path > other.path) or (self.__eq__(other))

	## this is the python object hash, not the file hash
	## you need this for set(someList) to work when someList
	## contains jamdupesFile objects
	def __hash__(self):
		x = hashlib.sha1()
		x.update(self.path.encode('utf-8'))
		y = x.hexdigest()
		result = int(y, 16)
		return result

	def size(self):
		return os.path.getsize(self.path)

	def isLink(self):
		return os.path.islink(self.path)

	def isReadable(self):
		return os.access(self.path, os.R_OK)

	def hashHeader(self):
		chunkSize = args.chunk
		hashState = hashlib.sha1()
		fp = open(self.path, "rb")
		hashState.update(fp.read(chunkSize))
		fp.close()
		return hashState.hexdigest()

	def hashWholeFile(self):
		if (self.hash == ''):
			chunkSize = args.chunk
			chunks = math.ceil(self.size()/chunkSize) + 1
			hashState = hashlib.sha1()
			fp = open(self.path, "rb")
			for i in range(0, chunks):
				chunk = fp.read(chunkSize)
				hashState.update(chunk)
			self.hash = hashState.hexdigest()
		return self.hash

def listFilesNonRecursive(path):
	if os.path.isfile(path):
		output = [jamdupesFile(path)]
	else:
		output = []
		files = [os.path.realpath(os.path.join(path,f)) for f in os.listdir(path)
			if os.path.isfile(os.path.join(path, f))]
		for file in files:
			output.append(jamdupesFile(file))
	return output

def listFilesRecursive(path):
	if os.path.isfile(path):
		output = [jamdupesFile(path)]
	else:
		output = []
		for root, dirnames, files in os.walk(path):
			for file in files:
				output.append(jamdupesFile(os.path.join(root, file)))
	return output

def parseArguments():
	## forgive me, terminal for I have sinned.
	## but this is much more readable than breaking them into 80 char
	## columns
	parser = argparse.ArgumentParser(prog='jamdupes', description='jamdupes very quickly finds duplicate files within given directories')
	parser.add_argument(dest='nonrecurseDirectories', default=[], action='append', nargs='*', metavar="DIRECTORY")
	parser.add_argument('-n', '--noempty', dest='ignoreZeros', action='store_const', const=True, default=False, help='ignore zero-length files')

	parser.add_argument('-1', '--sameline', dest='omitfirst', action='store_const', const=True, default=False, help='list all matching files on one line, separated by spaces.')
	#parser.add_argument('-f', '--omitfirst', dest='omitfirst', action='store_const', const=True, default=False, help='omit the first copy of a file found. This may be a random file from the set of matching files.')
	parser.add_argument('-s', '--symlinks', dest='followSymlinks', action='store_const', const=True, default=False, help='follow symlinks')
	parser.add_argument('-S', '--size', dest='showSizeOfFiles', action='store_const', const=True, default=False, help='show size of duplicate files')
	parser.add_argument('-R', '--recurse:', dest='recurseDirectories', default=[], action='append', nargs='+', metavar='DIRECTORY', help="recurse into *all* following directories")
	parser.add_argument('-r', '--recurse', dest='recurseDirectories', default=[], action='append', nargs=1, metavar='DIRECTORY', help="recurse into the following directory")
	#parser.add_argument('-q', '--quiet', dest='quiet', default=False, action='store_const', const=True, help="hide progress bar")

	parser.add_argument('-c', '--chunk', dest='chunk', default=10000000, action='store_const', const=True, help='initial test chunk size for large files in bytes. default: 10MB')
	global args
	args = parser.parse_args()

	## flattening the directory lists. code from
	## http://stackoverflow.com/questions/11264684/flatten-list-of-lists
	## thanks to Paul Seeb for this snippet.
	args.recurseDirectories = [val for sublist in args.recurseDirectories for val in sublist]
	args.nonrecurseDirectories = [val for sublist in args.nonrecurseDirectories for val in sublist]
	## end snippet

def getFilesToIndex():
	filesToIndex = []

	for directory in args.nonrecurseDirectories:
			files = listFilesNonRecursive(directory)
			filesToIndex.extend(files)

	for directory in args.recurseDirectories:
		files = listFilesRecursive(directory)
		filesToIndex.extend(files)

	return set(filesToIndex)


if __name__ == "__main__":
	try:
		# parse commandline arguments
		parseArguments()

		# get a preliminary list of files to index
		filesToIndex = getFilesToIndex()
		#print(filesToIndex)

		# srip out symlinks, if needed
		if (not args.followSymlinks):
			symlinks = []
			for file in filesToIndex:
				if file.isLink():
					symlinks.append(file)
			filesToIndex = filesToIndex.difference(symlinks)

		# turn this list into a fancy dictionary
		# keys = file sizes
		# values = list of jamdupesFile objects
		filesToIndex = jamdupesDictionary(filesToIndex)

		# strip out zero-length files if needed
		if (args.ignoreZeros):
			filesToIndex.trimZeroKey()

		# strip out unique-length files
		filesToIndex.trimKeysWithOnlyOneValue()

		# count the number of bytes to index
		bytesToIndex = 0
		fileCount = 0
		for key in filesToIndex.keys():
			bytesToIndex = bytesToIndex + (key * len(filesToIndex[key]))
			fileCount = fileCount + len(filesToIndex[key])
		print("bytes to index: ", bytesToIndex)
		print("files to index: ", fileCount)

		for file in filesToIndex:
			try:
				pass
			except PermissionError:
				sys.stderr.write("Access Denied: " + file.path + "\n")
	except (KeyboardInterrupt):
		pass
