#!/usr/bin/env python3
# -*- coding: utf-8 -*-

__author__ = "Jim Male <jmale1@gmail.com>"
__copyright__ = "Copyright (c) 2016"
__credits__ = ["Jim Male <jmale1@gmail.com>"]
__license__ = "BSD-3"

import os
import sys
import math
import argparse
import hashlib
import collections
import time

try:
	import progressbar
except ImportError:
	progressbar = None
	print("couldn't locate progress bar library")

class jamdupesDictionary(collections.defaultdict):
	def __init__(self):
		self.default_factory = list
	def __init__(self, collection):
		self.default_factory = list
		for item in collection:
			assert(type(item) == jamdupesFile)
			self.insertJamdupesFile(item)
	def trimKeysWithOnlyOneValue(self):
		tmpkeys = list(self.keys())
		for key in tmpkeys:
			if (len(self[key]) <= 1):
				del self[key]
	def trimZeroKey(self):
		keysToDelete = []
		for k in self.keys():
			if (k[0] == 0):
				keysToDelete.append(k)
		for k in keysToDelete:
			del self[k]

	def trimIdenticalFiles(self):
		keysToDelete = []
		for k in self.keys():
			if (self[k][0].size() == self[k][0].offset):
				keysToDelete.append(k)
		for k in keysToDelete:
			for f in self[k]:
				print("Duplicate: " + f.path)
			print("")
			del self[k]

	def insertJamdupesFile(self, jdFile):
		self[jdFile.tupleState()].append(jdFile)

	def printContents(self):
		print('-'*8)
		if (len(self.keys()) > 0):
			for k in self.keys():
				print(k)
				for f in self[k]:
					print("\t" + f.__repr__())
		else:
			print("<Empty>")
		print('-'*8)

## helpful help from
## http://pythoncentral.io/how-to-sort-a-list-tuple-or-object-with-sorted-in-python/
class jamdupesFile:
	def __init__(self, path):
		self.path = path
		self.hashState = hashlib.sha1()
		self.offset = 0

	def __repr__(self):
		return '<{}: {}>'.format(self.__class__.__name__, self.path)

	def __lt__(self, other):
		return self.path < other.path

	def __le__(self, other):
		return (self.path < other.path) or (self.__eq__(other))

	def __eq__(self, other):
		return os.path.samefile(self.path, other.path)

	def __ne__(self, other):
		return (not __eq__(other))

	def __gt__(self, other):
		return self.path > other.path

	def __ge__(self, other):
		return (self.path > other.path) or (self.__eq__(other))

	## this is the python object hash, not the file hash
	## you need this for set(someList) to work when someList
	## contains jamdupesFile objects
	def __hash__(self):
		x = hashlib.sha1()
		x.update(self.path.encode('utf-8'))
		y = x.hexdigest()
		result = int(y, 16)
		return result

	def size(self):
		return os.path.getsize(self.path)

	def tupleState(self):
		return (self.size(), self.offset, self.hashState.hexdigest())

	def isLink(self):
		return os.path.islink(self.path)

	def isReadable(self):
		return os.access(self.path, os.R_OK)

	def hashChunk(self):
		if(self.offset < self.size()):
			fp = open(self.path, "rb")
			fp.seek(self.offset)
			self.hashState.update(fp.read(args.chunk))
			fp.close()
			self.offset = min(self.size(), (self.offset + args.chunk))

def listFilesNonRecursive(path):
	if os.path.isfile(path):
		output = [jamdupesFile(path)]
	else:
		output = []
		files = [os.path.realpath(os.path.join(path,f)) for f in os.listdir(path)
			if os.path.isfile(os.path.join(path, f))]
		for file in files:
			output.append(jamdupesFile(file))
	return output

def listFilesRecursive(path):
	if os.path.isfile(path):
		output = [jamdupesFile(path)]
	else:
		output = []
		for root, dirnames, files in os.walk(path):
			for file in files:
				output.append(jamdupesFile(os.path.join(root, file)))
	return output

def parseArguments():
	## forgive me, terminal for I have sinned.
	## but this is much more readable than breaking them into 80 char
	## columns
	parser = argparse.ArgumentParser(prog='jamdupes', description='jamdupes very quickly finds duplicate files within given directories')
	parser.add_argument(dest='nonrecurseDirectories', default=[], action='append', nargs='*', metavar="DIRECTORY")
	parser.add_argument('-n', '--noempty', dest='ignoreZeros', action='store_const', const=True, default=False, help='ignore zero-length files')

	parser.add_argument('-1', '--sameline', dest='omitfirst', action='store_const', const=True, default=False, help='list all matching files on one line, separated by spaces.')
	#parser.add_argument('-f', '--omitfirst', dest='omitfirst', action='store_const', const=True, default=False, help='omit the first copy of a file found. This may be a random file from the set of matching files.')
	parser.add_argument('-s', '--symlinks', dest='followSymlinks', action='store_const', const=True, default=False, help='follow symlinks')
	parser.add_argument('-S', '--size', dest='showSizeOfFiles', action='store_const', const=True, default=False, help='show size of duplicate files')
	parser.add_argument('-R', '--recurse:', dest='recurseDirectories', default=[], action='append', nargs='+', metavar='DIRECTORY', help="recurse into *all* following directories")
	parser.add_argument('-r', '--recurse', dest='recurseDirectories', default=[], action='append', nargs=1, metavar='DIRECTORY', help="recurse into the following directory")
	#parser.add_argument('-q', '--quiet', dest='quiet', default=False, action='store_const', const=True, help="hide progress bar")

	parser.add_argument('-c', '--chunk', dest='chunk', default=10000000, action='store_const', const=True, help='initial test chunk size for large files in bytes. default: 10MB')
	parser.add_argument('--verbose', '-v', action='count', default=0)
	global args
	args = parser.parse_args()

	## flattening the directory lists. code from
	## http://stackoverflow.com/questions/11264684/flatten-list-of-lists
	## thanks to Paul Seeb for this snippet.
	args.recurseDirectories = [val for sublist in args.recurseDirectories for val in sublist]
	args.nonrecurseDirectories = [val for sublist in args.nonrecurseDirectories for val in sublist]
	## end snippet

def getFilesToIndex():
	filesToIndex = []

	for directory in args.nonrecurseDirectories:
			files = listFilesNonRecursive(directory)
			filesToIndex.extend(files)

	for directory in args.recurseDirectories:
		files = listFilesRecursive(directory)
		filesToIndex.extend(files)

	return set(filesToIndex)


if __name__ == "__main__":
	try:
		# parse commandline arguments
		parseArguments()

		# get a preliminary list of files to index
		filesToIndex = getFilesToIndex()
		#print(filesToIndex)

		# srip out symlinks, if needed
		if (not args.followSymlinks):
			symlinks = []
			for file in filesToIndex:
				if file.isLink():
					symlinks.append(file)
			filesToIndex = filesToIndex.difference(symlinks)

		# turn this list into a fancy dictionary
		# keys = file sizes
		# values = list of jamdupesFile objects
		filesToIndex = jamdupesDictionary(filesToIndex)

		if(args.verbose >= 2):
			print("Initial file list:")
			filesToIndex.printContents()
			print("")

		# strip out zero-length files if needed
		if (args.ignoreZeros):
			filesToIndex.trimZeroKey()
			if(args.verbose >= 2):
				print("After removing zero-length files:")
				filesToIndex.printContents()
				print("")

		# strip out unique-length files
		filesToIndex.trimKeysWithOnlyOneValue()
		if(args.verbose >= 2):
			print("After removing unique-length files:")
			filesToIndex.printContents()
			print("")

		while(len(filesToIndex.keys()) > 0):
			if(args.verbose >= 2):
				print("*LOOP*")
			k = list(filesToIndex.keys())[0]
			files = filesToIndex[k]
			del filesToIndex[k]

			for f in files:
				f.hashChunk()
				filesToIndex.insertJamdupesFile(f)
			filesToIndex.trimKeysWithOnlyOneValue()
			filesToIndex.trimIdenticalFiles()
			if(args.verbose >= 2):
				filesToIndex.printContents()

	except (KeyboardInterrupt):
		pass
